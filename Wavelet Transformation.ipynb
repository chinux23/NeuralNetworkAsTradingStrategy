{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import sqrt\n",
    "from pytz import timezone\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import talib\n",
    "\n",
    "def get_CU():\n",
    "    import dovahkiin as dk\n",
    "    dp = dk.DataParser()\n",
    "    X = dp.get_data(\"cu\")\n",
    "    return X\n",
    "\n",
    "def get_SP500():\n",
    "    import pandas_datareader as pdr    \n",
    "    SP500 = pdr.get_data_yahoo('^GSPC')\n",
    "    return SP500\n",
    "\n",
    "def get_X_data():\n",
    "    import dovahkiin as dk\n",
    "    dp = dk.DataParser()\n",
    "    X = dp.get_data(\"cu\")\n",
    "    return X\n",
    "\n",
    "X = get_X_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = (12, 9)\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"HLC\"] = (X.high + X.low + X.close) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"return\"] = X.HLC.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"return\"] = X[\"return\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "from statsmodels.robust import stand_mad\n",
    "\n",
    "# Wavelet Decomposition\n",
    "level = 9\n",
    "haar = pywt.Wavelet(\"haar\")\n",
    "coeffs = pywt.wavedec(X[\"return\"].values, haar, level=9)\n",
    "recomposed_return = pywt.waverec(coeffs, haar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.94567017e-20,  -1.52746431e-05,  -3.30791130e-04, ...,\n",
       "        -4.46399095e-04,   3.44784337e-04,   3.44784337e-04])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomposed_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2003-08-01 09:00:00+08:00    6.945670e-20\n",
       "2003-08-01 09:01:00+08:00    7.453890e-20\n",
       "2003-08-01 09:02:00+08:00    1.626303e-19\n",
       "2003-08-01 09:03:00+08:00    1.626303e-19\n",
       "2003-08-01 09:04:00+08:00    2.710505e-20\n",
       "2003-08-01 09:05:00+08:00   -2.710505e-20\n",
       "2003-08-01 09:06:00+08:00    0.000000e+00\n",
       "2003-08-01 09:07:00+08:00   -2.710505e-20\n",
       "2003-08-01 09:08:00+08:00   -5.421011e-20\n",
       "2003-08-01 09:09:00+08:00   -1.355253e-20\n",
       "2003-08-01 09:10:00+08:00   -2.168404e-19\n",
       "2003-08-01 09:11:00+08:00   -8.131516e-20\n",
       "2003-08-01 09:12:00+08:00   -2.710505e-20\n",
       "2003-08-01 09:13:00+08:00   -4.065758e-20\n",
       "2003-08-01 09:14:00+08:00   -3.388132e-20\n",
       "2003-08-01 09:15:00+08:00   -2.710505e-20\n",
       "2003-08-01 09:16:00+08:00   -5.421011e-20\n",
       "2003-08-01 09:17:00+08:00   -5.421011e-20\n",
       "2003-08-01 09:18:00+08:00   -1.694066e-20\n",
       "2003-08-01 09:19:00+08:00   -2.710505e-20\n",
       "2003-08-01 09:20:00+08:00    2.710505e-20\n",
       "2003-08-01 09:21:00+08:00    2.710505e-20\n",
       "2003-08-01 09:22:00+08:00   -2.710505e-20\n",
       "2003-08-01 09:23:00+08:00    0.000000e+00\n",
       "2003-08-01 09:24:00+08:00   -2.710505e-20\n",
       "2003-08-01 09:25:00+08:00   -2.032879e-20\n",
       "2003-08-01 09:26:00+08:00    2.710505e-20\n",
       "2003-08-01 09:27:00+08:00    0.000000e+00\n",
       "2003-08-01 09:28:00+08:00   -1.355253e-20\n",
       "2003-08-01 09:29:00+08:00   -6.776264e-21\n",
       "                                 ...     \n",
       "2017-07-04 14:30:00+08:00   -1.084202e-19\n",
       "2017-07-04 14:31:00+08:00   -5.421011e-20\n",
       "2017-07-04 14:32:00+08:00   -2.032879e-20\n",
       "2017-07-04 14:33:00+08:00    5.421011e-20\n",
       "2017-07-04 14:34:00+08:00    6.098637e-20\n",
       "2017-07-04 14:35:00+08:00    5.421011e-20\n",
       "2017-07-04 14:36:00+08:00    4.065758e-20\n",
       "2017-07-04 14:37:00+08:00    2.710505e-20\n",
       "2017-07-04 14:38:00+08:00    1.084202e-19\n",
       "2017-07-04 14:39:00+08:00    1.084202e-19\n",
       "2017-07-04 14:40:00+08:00    8.131516e-20\n",
       "2017-07-04 14:41:00+08:00   -2.710505e-20\n",
       "2017-07-04 14:42:00+08:00    2.710505e-20\n",
       "2017-07-04 14:43:00+08:00    0.000000e+00\n",
       "2017-07-04 14:44:00+08:00    2.710505e-20\n",
       "2017-07-04 14:45:00+08:00   -5.421011e-20\n",
       "2017-07-04 14:46:00+08:00   -5.421011e-20\n",
       "2017-07-04 14:47:00+08:00   -5.421011e-20\n",
       "2017-07-04 14:48:00+08:00   -5.421011e-20\n",
       "2017-07-04 14:49:00+08:00    1.084202e-19\n",
       "2017-07-04 14:50:00+08:00    5.421011e-20\n",
       "2017-07-04 14:51:00+08:00   -4.065758e-20\n",
       "2017-07-04 14:52:00+08:00   -4.065758e-20\n",
       "2017-07-04 14:53:00+08:00   -2.710505e-19\n",
       "2017-07-04 14:54:00+08:00   -4.336809e-19\n",
       "2017-07-04 14:55:00+08:00   -1.626303e-19\n",
       "2017-07-04 14:56:00+08:00   -1.219727e-19\n",
       "2017-07-04 14:57:00+08:00    0.000000e+00\n",
       "2017-07-04 14:58:00+08:00    0.000000e+00\n",
       "2017-07-04 14:59:00+08:00   -5.421011e-20\n",
       "Name: return, Length: 958635, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"return\"] - recomposed_return[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.94567017e-20,  -1.52746431e-05,  -3.30791130e-04, ...,\n",
       "        -3.99795386e-04,  -4.46399095e-04,   3.44784337e-04])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomposed_return[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = recomposed_return[:-1] - X[\"return\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2389725842013506e-13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(diff).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet De-noising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = stand_mad(coeffs[-1])\n",
    "uthresh = sigma*np.sqrt(2*np.log(len(X[\"return\"].values)))\n",
    "denoised = coeffs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised[1:] = (pywt.threshold(i, value=uthresh) for i in denoised[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_return = pywt.waverec(denoised, haar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"denoised\"] = denoised_return[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 958636 elements\n",
      "Total absolute difference: 230.6085907747903\n",
      "Correlation between denoised and original: 0.9060392654130378\n"
     ]
    }
   ],
   "source": [
    "diff = denoised_return[:-1] - X[\"return\"].values\n",
    "correlation = np.corrcoef(denoised_return[:-1], X[\"return\"].values)\n",
    "print(\"There are total of {} elements\".format(len(denoised_return)))\n",
    "print(\"Total absolute difference: {}\".format(np.abs(diff).sum()))\n",
    "print(\"Correlation between denoised and original: {}\".format(correlation[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1188c7b00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"denoised\": denoised_return[1:]}, index=X.index).plot()\n",
    "X[\"return\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 33.35%\n",
      "Train: 66.65%\n"
     ]
    }
   ],
   "source": [
    "X_train = X[\"2012\":\"2015\"]\n",
    "X_test = X[\"2016\":]\n",
    "print(\"Test: {:.2f}%\".format(100 * len(X_test)/len(X[\"2012\":])))\n",
    "print(\"Train: {:.2f}%\".format(100 * len(X_train)/len(X[\"2012\":])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X[\"return\"].shift(-1)\n",
    "y = y.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y[\"2012\":\"2015\"]\n",
    "y_test  = y[\"2016\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['HLC']\n",
    "del X_train['open']\n",
    "del X_train['high'] \n",
    "del X_train['low']\n",
    "del X_train['close']\n",
    "del X_train['volume']\n",
    "del X_train['openint']\n",
    "\n",
    "del X_test[\"HLC\"]\n",
    "del X_test['open']\n",
    "del X_test['high'] \n",
    "del X_test['low']\n",
    "del X_test['close']\n",
    "del X_test['volume']\n",
    "del X_test['openint']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize de-noised return\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"denoised_scaled\"] = scaler.fit_transform(pd.DataFrame(X_train[\"denoised\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"denoised_scaled\"] = scaler.transform(pd.DataFrame(X_test[\"denoised\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_series_step=4\n",
    "\n",
    "def timeseries_to_supervised(raw_time_series, lag):\n",
    "    p = {}\n",
    "    for i in range(1, lag+1):\n",
    "        p[\"{}\".format(i)] = raw_time_series.shift(i).fillna(0)\n",
    "    p[\"0\"] = raw_time_series\n",
    "    \n",
    "    supervised_data = pd.Panel(p)\n",
    "    return supervised_data\n",
    "\n",
    "def non_shuffling_train_test_split(X, y, test_size=0.2):\n",
    "    i = int((1 - test_size) * X.shape[0]) + 1\n",
    "    X_train, X_test = np.split(X, [i])\n",
    "    y_train, y_test = np.split(y, [i])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def create_supervised_X(raw_time_series, lag):\n",
    "    supervised_X = timeseries_to_supervised(raw_time_series, lag)\n",
    "    swaped_supervised_X = supervised_X.swapaxes(0, 1)\n",
    "    return swaped_supervised_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = create_supervised_X(pd.DataFrame(X_train[\"denoised_scaled\"]), time_series_step)\n",
    "X_test  = create_supervised_X(pd.DataFrame(X_test[\"denoised_scaled\"]), time_series_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "y_scaler = MinMaxScaler()\n",
    "y_train = y_scaler.fit_transform(y_train)\n",
    "y_test = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333465, 5, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166845, 5, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(128, batch_input_shape=(batch_size, time_series_step+1, features), stateful=False, \n",
    "         return_sequences=True, \n",
    "         activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "model.add(\n",
    "    LSTM(128, stateful=False, \n",
    "         return_sequences=True, \n",
    "         activation=\"relu\"\n",
    "        ))\n",
    "    \n",
    "model.add(LSTM(32, activation=\"relu\", stateful=True))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adadelta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 333465 samples, validate on 166845 samples\n",
      "Epoch 1/5\n",
      "333465/333465 [==============================] - 720s - loss: 3.5642e-04 - val_loss: 0.0043\n",
      "Epoch 2/5\n",
      "333465/333465 [==============================] - 712s - loss: 3.9261e-05 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "333465/333465 [==============================] - 690s - loss: 3.6623e-05 - val_loss: 0.0010\n",
      "Epoch 4/5\n",
      "333465/333465 [==============================] - 709s - loss: 3.5497e-05 - val_loss: 6.3225e-04\n",
      "Epoch 5/5\n",
      "333465/333465 [==============================] - 701s - loss: 3.4838e-05 - val_loss: 4.3346e-04\n"
     ]
    }
   ],
   "source": [
    "history = LossHistory()\n",
    "history4 = model.fit(X_train.values, \n",
    "                     y_train, \n",
    "                     epochs=5, \n",
    "                     batch_size=batch_size, \n",
    "                     shuffle=False, \n",
    "                     validation_data=(X_test.values, y_test),\n",
    "                     callbacks=[history]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_history_val_loss = history.history['val_loss'] + history2.history['val_loss'] + history3.history['val_loss'] + history3.history['val_loss']\n",
    "total_history_loss = history.history['loss'] + history2.history['loss'] + history3.history['loss'] + history3.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu0AAAImCAYAAADnkbQQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d815a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "# plt.plot(SAE_results[0].history['loss'][:size_limit])\n",
    "# plt.plot(history.history['loss'][:size_limit])\n",
    "# plt.plot(deep_results[0].history['loss'][:size_limit])\n",
    "plt.plot(total_history_val_loss)\n",
    "plt.plot(total_history_loss)\n",
    "plt.title('1min Wavelet LSTM Predictor')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Validation Loss', \"Training Loss\", ], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"Wavelet_LSTM_1min_stateless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict_scaled = model.predict(X_test.values, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166845"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict_scaled.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_predict = y_scaler.inverse_transform(y_test_predict_scaled)\n",
    "y_test_predict = y_test_predict.reshape(y_test_predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "y_test_actual = y_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166845"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166845"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_actual.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.04470938],\n",
       "       [ 0.04470938,  1.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(y_test_predict, y_test_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y[\"2016\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[\"predict\"] = y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test[\"predict_scaled\"] = y_test_predict_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571092</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.560160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548666</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.566012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.548693</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.570617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563428</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.573730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.555037</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.575134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.552425</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.575130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.550357</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.575102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.536375</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.575101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.532962</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.575048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.535060</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.549666</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.559384</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.575010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.539749</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.575041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.546030</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.575046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.530955</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.575054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.539651</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.571759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.559046</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.573027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.563766</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.574051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.562418</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.574772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.540597</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.575114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.559732</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.575118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.553867</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.575131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.552725</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.575134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.575122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.553196</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.575113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.557103</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.575115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.554794</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.575115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.551362</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.575122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.553738</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.575123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.550705</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.575125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166815</th>\n",
       "      <td>0.556387</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166816</th>\n",
       "      <td>0.554382</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166817</th>\n",
       "      <td>0.553897</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166818</th>\n",
       "      <td>0.555051</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166819</th>\n",
       "      <td>0.551810</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166820</th>\n",
       "      <td>0.554432</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166821</th>\n",
       "      <td>0.555379</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166822</th>\n",
       "      <td>0.550321</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166823</th>\n",
       "      <td>0.548529</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166824</th>\n",
       "      <td>0.553550</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166825</th>\n",
       "      <td>0.557194</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166826</th>\n",
       "      <td>0.553481</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166827</th>\n",
       "      <td>0.551531</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166828</th>\n",
       "      <td>0.554495</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166829</th>\n",
       "      <td>0.558214</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166830</th>\n",
       "      <td>0.557035</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166831</th>\n",
       "      <td>0.555874</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166832</th>\n",
       "      <td>0.557332</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166833</th>\n",
       "      <td>0.551508</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166834</th>\n",
       "      <td>0.553945</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166835</th>\n",
       "      <td>0.556299</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166836</th>\n",
       "      <td>0.556421</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166837</th>\n",
       "      <td>0.559424</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166838</th>\n",
       "      <td>0.564081</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166839</th>\n",
       "      <td>0.557668</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166840</th>\n",
       "      <td>0.556037</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166841</th>\n",
       "      <td>0.550313</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166842</th>\n",
       "      <td>0.549764</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166843</th>\n",
       "      <td>0.559085</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166844</th>\n",
       "      <td>0.555023</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.575157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166845 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0   predict  predict_scaled\n",
       "0       0.571092  0.000436        0.560160\n",
       "1       0.548666  0.000933        0.566012\n",
       "2       0.548693  0.001324        0.570617\n",
       "3       0.563428  0.001588        0.573730\n",
       "4       0.555037  0.001707        0.575134\n",
       "5       0.552425  0.001707        0.575130\n",
       "6       0.550357  0.001704        0.575102\n",
       "7       0.536375  0.001704        0.575101\n",
       "8       0.532962  0.001700        0.575048\n",
       "9       0.535060  0.001696        0.575000\n",
       "10      0.549666  0.001696        0.575000\n",
       "11      0.559384  0.001696        0.575010\n",
       "12      0.539749  0.001699        0.575041\n",
       "13      0.546030  0.001700        0.575046\n",
       "14      0.530955  0.001700        0.575054\n",
       "15      0.539651  0.001421        0.571759\n",
       "16      0.559046  0.001528        0.573027\n",
       "17      0.563766  0.001615        0.574051\n",
       "18      0.562418  0.001676        0.574772\n",
       "19      0.540597  0.001705        0.575114\n",
       "20      0.559732  0.001706        0.575118\n",
       "21      0.553867  0.001707        0.575131\n",
       "22      0.552725  0.001707        0.575134\n",
       "23      0.554545  0.001706        0.575122\n",
       "24      0.553196  0.001705        0.575113\n",
       "25      0.557103  0.001705        0.575115\n",
       "26      0.554794  0.001705        0.575115\n",
       "27      0.551362  0.001706        0.575122\n",
       "28      0.553738  0.001706        0.575123\n",
       "29      0.550705  0.001706        0.575125\n",
       "...          ...       ...             ...\n",
       "166815  0.556387  0.001709        0.575157\n",
       "166816  0.554382  0.001709        0.575157\n",
       "166817  0.553897  0.001709        0.575157\n",
       "166818  0.555051  0.001709        0.575157\n",
       "166819  0.551810  0.001709        0.575157\n",
       "166820  0.554432  0.001709        0.575157\n",
       "166821  0.555379  0.001709        0.575157\n",
       "166822  0.550321  0.001709        0.575157\n",
       "166823  0.548529  0.001709        0.575157\n",
       "166824  0.553550  0.001709        0.575157\n",
       "166825  0.557194  0.001709        0.575157\n",
       "166826  0.553481  0.001709        0.575157\n",
       "166827  0.551531  0.001709        0.575157\n",
       "166828  0.554495  0.001709        0.575157\n",
       "166829  0.558214  0.001709        0.575157\n",
       "166830  0.557035  0.001709        0.575157\n",
       "166831  0.555874  0.001709        0.575157\n",
       "166832  0.557332  0.001709        0.575157\n",
       "166833  0.551508  0.001709        0.575157\n",
       "166834  0.553945  0.001709        0.575157\n",
       "166835  0.556299  0.001709        0.575157\n",
       "166836  0.556421  0.001709        0.575157\n",
       "166837  0.559424  0.001709        0.575157\n",
       "166838  0.564081  0.001709        0.575157\n",
       "166839  0.557668  0.001709        0.575157\n",
       "166840  0.556037  0.001709        0.575157\n",
       "166841  0.550313  0.001709        0.575157\n",
       "166842  0.549764  0.001709        0.575157\n",
       "166843  0.559085  0.001709        0.575157\n",
       "166844  0.555023  0.001709        0.575157\n",
       "\n",
       "[166845 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
